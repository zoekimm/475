{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Final Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0dbm5c9Z2qg",
        "outputId": "66ec911d-4d50-481f-dd6e-9111a48a0884"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/zoekimm/475/blob/main/scripts/english-russian.txt.zip?raw=true\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bsqt-m-rZ6Z7",
        "outputId": "2ee42c12-5ada-4902-f93c-99e1a6cb805f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 11:09:57--  https://github.com/zoekimm/475/blob/main/scripts/english-russian.txt.zip?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/zoekimm/475/raw/main/scripts/english-russian.txt.zip [following]\n",
            "--2021-12-10 11:09:57--  https://github.com/zoekimm/475/raw/main/scripts/english-russian.txt.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zoekimm/475/main/scripts/english-russian.txt.zip [following]\n",
            "--2021-12-10 11:09:57--  https://raw.githubusercontent.com/zoekimm/475/main/scripts/english-russian.txt.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12314874 (12M) [application/zip]\n",
            "Saving to: ‘english-russian.txt.zip?raw=true.1’\n",
            "\n",
            "english-russian.txt 100%[===================>]  11.74M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-12-10 11:09:58 (117 MB/s) - ‘english-russian.txt.zip?raw=true.1’ saved [12314874/12314874]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/english-russian.txt.zip?raw=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UDr6-XccwBH",
        "outputId": "3dc84c9c-57ce-485b-954e-b26501847de8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/english-russian.txt.zip?raw=true\n",
            "replace english-russian.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: english-russian.txt     \n",
            "replace __MACOSX/._english-russian.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._english-russian.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrvhhySvGanD"
      },
      "source": [
        "input = [] #English\n",
        "output = [] #Russian\n",
        "\n",
        "with open('./english-russian.txt', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        sentences = line.split('\\t')[:2]\n",
        "        input.append(sentences[1])\n",
        "        output.append(sentences[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTK_O7yiodJI"
      },
      "source": [
        "import string\n",
        "\n",
        "#remove punctuations\n",
        "input = [''.join(word for word in sentence if word not in string.punctuation) for sentence in input]\n",
        "output = [''.join(word for word in sentence if word not in string.punctuation) for sentence in output]\n",
        "\n",
        "#need to add SOS EOS token"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnsQHA6hli5W"
      },
      "source": [
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "class Vocab:\n",
        "  def __init__(self, li): \n",
        "      #li = list of sentencs\n",
        "        #self.language = language #eng OR rus\n",
        "        self.li = li\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.listOfVocab = self.get_vocab()\n",
        "        self.word2count = self.get_word2count()\n",
        "        self.word2index = self.get_word2index()\n",
        "        self.index2word = self.get_index2word()\n",
        "        self.max_length = max([len(sentence.split()) for sentence in self.li])\n",
        "        self.encoded = self.get_encoded()\n",
        "\n",
        "  def get_vocab(self): \n",
        "    temp = []\n",
        "    for i in self.li:\n",
        "      temp.append(i.split())\n",
        "    return list(chain(*temp)) #list of vocab\n",
        "\n",
        "  def get_word2count(self):\n",
        "    return Counter(self.listOfVocab)\n",
        "\n",
        "  def get_word2index(self):\n",
        "    self.tokenizer.fit_on_texts(self.li)\n",
        "    return self.tokenizer.word_index\n",
        "\n",
        "  def get_index2word(self):\n",
        "    return self.tokenizer.index_word\n",
        "\n",
        "  def get_encoded(self):\n",
        "    sequence = self.tokenizer.texts_to_sequences(self.li)\n",
        "    sequence = pad_sequences(sequence, self.max_length, padding='post')\n",
        "    return sequence"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecBku5ocOzv2"
      },
      "source": [
        "#teacher forcing\n",
        "\n",
        "output_in = []\n",
        "output_target = []\n",
        "for i in output:\n",
        "  output_in.append('<SOS> ' + i)\n",
        "  output_target.append(i + ' <EOS>')\n",
        "  \n",
        "rus_vocab = Vocab(input)\n",
        "eng_vocab_in = Vocab(output_in)\n",
        "eng_vocab_target = Vocab(output_target)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rus_vocab_size = len(rus_vocab.word2count)\n",
        "eng_vocab_size = len(eng_vocab_target.word2count)\n",
        "\n",
        "print(rus_vocab_size)\n",
        "print(eng_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuQuSZqKD_on",
        "outputId": "381ec659-f676-49d3-a497-98b1fa651472"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59814\n",
            "18829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "hidden_dim = 256 \n",
        "embedding_size = 256 \n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embededding_layer = tf.keras.layers.Embedding(rus_vocab_size, embedding_size)\n",
        "        self.lstm = tf.keras.layers.LSTM(hidden_dim, return_sequences=False, return_state=True)\n",
        "        \n",
        "    def call(self, x):\n",
        "        output = self.embededding_layer(x)\n",
        "        _, state_h, state_c = self.lstm(output)\n",
        "        states = (state_h, state_c)\n",
        "        return states\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embededding_layer = tf.keras.layers.Embedding(eng_vocab_size, embedding_size)\n",
        "        self.lstm = tf.keras.layers.LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
        "        self.dense_layer = tf.keras.layers.Dense(eng_vocab_size, activation='softmax')\n",
        "        \n",
        "    def call(self, x, initial_state):\n",
        "        output = self.embededding_layer(x)\n",
        "        output, state_h, state_c = self.lstm(output, initial_state = initial_state)\n",
        "        output = self.dense_layer(output)\n",
        "        states = (state_h, state_c)\n",
        "        return output, states"
      ],
      "metadata": {
        "id": "pcaJudIe0tFl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder()\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "encoder_states = encoder(encoder_inputs)\n",
        "\n",
        "decoder = Decoder()\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_outputs, _ = decoder(decoder_inputs, initial_state = encoder_states)\n",
        "\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "34P_WSkFCLMO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT1_lPDxDnu2",
        "outputId": "4a77d29b-dbaf-450d-8677-7beb84af8c16"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_1 (Encoder)            ((None, 256),        15837696    ['input_2[0][0]']                \n",
            "                                 (None, 256))                                                     \n",
            "                                                                                                  \n",
            " decoder (Decoder)              ((None, None, 18829  10184589    ['input_3[0][0]',                \n",
            "                                ),                                'encoder_1[0][0]',              \n",
            "                                 ((None, 256),                    'encoder_1[0][1]']              \n",
            "                                 (None, 256)))                                                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 26,022,285\n",
            "Trainable params: 26,022,285\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "encoder_input_arr = rus_vocab.get_encoded()\n",
        "decoder_input_arr = eng_vocab_in.get_encoded()\n",
        "decoder_target_arr = eng_vocab_target.get_encoded()\n",
        "print(encoder_input_arr.shape)\n",
        "print(decoder_input_arr.shape)\n",
        "print(decoder_target_arr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL_4OyZ51PWs",
        "outputId": "80fc2806-3e1e-4d27-f97d-189108895d70"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(363386, 80)\n",
            "(363386, 102)\n",
            "(363386, 102)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\")\n",
        "model.fit([encoder_input_arr, decoder_input_arr], decoder_target_arr, batch_size = batch_size, epochs = epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "FJLCe1goBhA5",
        "outputId": "6b65640e-ed19-424d-809d-a4ed289b1bbb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7941c1ed3b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_arr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1665, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 102) and (None, 102, 18829) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "\n",
        "#encoder_input = np.reshape(encoder_input, (encoder_input.shape[0], 1, encoder_input.shape[1]))\n",
        "\n",
        "#decoder_input = np.reshape(decoder_input, (decoder_input.shape[0], 1, decoder_input.shape[1]))\n",
        "\n",
        "#decoder_target = np.reshape(decoder_target, (decoder_target.shape[0], 1, decoder_target.shape[1]))"
      ],
      "metadata": {
        "id": "llgSVCtLwtT_"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCNXhR4wIrEz"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module): # shape (batch_size, maxlength)\n",
        "    def __init__(self, input_size, hidden_size, embedding_size = 50, num_layers)):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, 0.5)\n",
        "        self.hidden = hidden_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, (h_n, c_n) = self.rnn(x)\n",
        "        return output, (h_n, c_n)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, 0.5)\n",
        "        self.hidden = hidden_size\n",
        "\n",
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(self, encoder, decoder, hidden_size, num_class):\n",
        "        super(Seq2SeqModel, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.fc = nn.Linear(hidden_size, num_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0cjOaR1ExEF"
      },
      "source": [
        "n_decoder_tokens = len(rus_vocab.word2count)\n",
        "\n",
        "def batch_generator(X, y, batch_size):\n",
        "  while True:\n",
        "    for i in range(len(X)//batch_size):\n",
        "      encoder_input = np.zeros(batch_size, eng_vocab.max_length)\n",
        "      decoder_input = np.zeros(batch_size, rus_vocab.max_length)\n",
        "      target = np.zeros(batch_size, rus_vocab.max_length, n_decoder_tokens)\n",
        "      for j in range(batch_size):\n",
        "        index = i * batch_size + j\n",
        "        if index >= len(X):\n",
        "          break\n",
        "        input_text = X[index]\n",
        "        target_text = y[index]\n",
        "        for k, word in enumerate(input_text.split()):\n",
        "          encoder_input[j, k] = eng_vocab.word2index[word]\n",
        "        for k, word in enumerate(target_text.split()):\n",
        "          if k < len(target_text.split()) - 1:\n",
        "            decoder_input[j, k] = rus_vocab.word2index[word]\n",
        "          if k > 0:\n",
        "            target[j, k-1, rus_vocab.word2index[word]] = 1\n",
        "\n",
        "      yield ([encoder_input, decoder_input], target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCBfGRJLKVe-"
      },
      "source": [
        "def train(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
